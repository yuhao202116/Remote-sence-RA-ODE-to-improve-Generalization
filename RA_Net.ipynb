{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e5671d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f743bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Dataset ---------------------------\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = sorted(os.listdir(image_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.images[idx])\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = transforms.Compose([\n",
    "              transforms.Resize((256, 256), interpolation=Image.NEAREST),\n",
    "              transforms.Lambda(lambda x: torch.from_numpy(np.array(x)).long())\n",
    "            ])(mask)\n",
    "        \n",
    "        return image, mask\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e046872",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------- ASPP Module ---------------------------\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.atrous_block1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.atrous_block6 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=6, dilation=6)\n",
    "        self.atrous_block12 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12)\n",
    "        self.atrous_block18 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=18, dilation=18)\n",
    "        self.global_avg_pool = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        )\n",
    "        self.conv1x1 = nn.Conv2d(out_channels * 5, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        size = x.shape[2:]\n",
    "        out1 = self.atrous_block1(x) ## 1x1 Conv\n",
    "        out2 = self.atrous_block6(x) ## 3x3 Conv Padding = 6\n",
    "        out3 = self.atrous_block12(x) ## 3x3 Conv Padding = 12\n",
    "        out4 = self.atrous_block18(x) ## 3x3 Conv Padding = 18\n",
    "        out5 = self.global_avg_pool(x) ## 3x3 Conv Padding = 18\n",
    "        out5 = F.interpolate(out5, size=size, mode='bilinear', align_corners=True)\n",
    "        out = torch.cat([out1, out2, out3, out4, out5], dim=1)\n",
    "        return self.conv1x1(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b7a001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------- Segmentation Model ---------------------------\n",
    "class SegNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SegNet, self).__init__()\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        self.encoder = nn.Sequential(*list(resnet.children())[:-2])\n",
    "        self.aspp = ASPP(in_channels=2048, out_channels=256)\n",
    "        self.low_level_conv = nn.Conv2d(256, 48, kernel_size=1)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(256 + 48, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=8, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(256, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## x.shape = torch.Size([4, 1, 256, 256])\n",
    "        shallow = self.encoder[4](self.encoder[3](self.encoder[2](self.encoder[1](self.encoder[0](x)))))\n",
    "        x = self.encoder(x)\n",
    "        x = self.aspp(x) # torch.Size([1, 256, 8, 8])\n",
    "        x = F.interpolate(x, scale_factor=4, mode='bilinear', align_corners=True)\n",
    "        shallow = self.low_level_conv(shallow)\n",
    "        shallow = F.interpolate(shallow, size=x.shape[2:], mode='bilinear', align_corners=True)\n",
    "        x = torch.cat([x, shallow], dim=1)\n",
    "        return self.decoder(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccc2e422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------- Dice + CE Loss ---------------------------\n",
    "class DiceCELoss(nn.Module):\n",
    "    def __init__(self, weight_dice=1.0, weight_ce=1.0, smooth=1.0):\n",
    "        super(DiceCELoss, self).__init__()\n",
    "        self.weight_dice = weight_dice\n",
    "        self.weight_ce = weight_ce\n",
    "        self.smooth = smooth\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        ce_loss = self.ce(preds, targets)\n",
    "        dice_loss = self._dice_loss(preds, targets)\n",
    "        return self.weight_ce * ce_loss + self.weight_dice * dice_loss\n",
    "\n",
    "    def _dice_loss(self, preds, targets):\n",
    "        probs = torch.softmax(preds, dim=1)\n",
    "        targets_one_hot = F.one_hot(targets, num_classes=preds.shape[1]).permute(0, 3, 1, 2).float()\n",
    "        dims = (0, 2, 3)\n",
    "        intersection = torch.sum(probs * targets_one_hot, dims)\n",
    "        cardinality = torch.sum(probs + targets_one_hot, dims)\n",
    "        dice_score = (2. * intersection + self.smooth) / (cardinality + self.smooth)\n",
    "        return 1 - dice_score.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b32b1a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------- Training and Validation ---------------------------\n",
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for imgs, masks in loader:\n",
    "        imgs, masks = imgs.cuda(), masks.cuda()\n",
    "        preds = model(imgs) ## preds:torch.Size([4, 2, 128, 128])  masks:torch.Size([4, 256, 256]\n",
    "        \n",
    "        loss = criterion(preds, masks)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader) # average_loss\n",
    "\n",
    "def validate_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in loader:\n",
    "            imgs, masks = imgs.cuda(), masks.cuda()\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds, masks)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1e58cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/root/workspace/ssd/txj_workspace/hawkyu/hawkyu/remote_sence/dataset/data\"\n",
    "img_path = data_path + '/JPEGImages'\n",
    "mask_path = data_path + '/Annotations'\n",
    "models_path = data_path + '/Models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6168f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------- Train Script ---------------------------\n",
    "def train():\n",
    "    image_dir = img_path\n",
    "    mask_dir = mask_path\n",
    "    epoch_num = 20\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "\n",
    "    dataset = SegmentationDataset(image_dir, mask_dir, transform = transform)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=4, shuffle=False)\n",
    "\n",
    "\n",
    "    ## 掩码背景全为零\n",
    "\n",
    "    model = SegNet(num_classes=5).cuda()\n",
    "    criterion = DiceCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    for epoch in range(1, epoch_num):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "        val_loss = validate_epoch(model, val_loader, criterion)\n",
    "\n",
    "        print(f\"Epoch {epoch}: Train Loss={train_loss:.4f} | Val Loss={val_loss:.4f}\")\n",
    "\n",
    "        torch.save(model.state_dict(), f\"model_epoch{epoch}.pth\")\n",
    "    \n",
    "\n",
    "    save_path = os.path.join(models_path, \"Train_01.pth\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(\"Model saved successfully!\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bb0690",
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a29051",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3773f870",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfad981",
   "metadata": {},
   "source": [
    "## calcuate miou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a7a9af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mIoU(preds, labels, num_classes):\n",
    "    \"\"\"\n",
    "    计算 mean IoU\n",
    "    preds: 预测结果，Tensor，形状为 [B, H, W]，取值为类别索引\n",
    "    labels: 真实标签，Tensor，形状为 [B, H, W]，取值为类别索引\n",
    "    num_classes: 类别数\n",
    "    \"\"\"\n",
    "    ious = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = (preds == cls)\n",
    "        target_inds = (labels == cls)\n",
    "        intersection = (pred_inds & target_inds).sum().item()\n",
    "        union = (pred_inds | target_inds).sum().item()\n",
    "\n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))  # 当前类别在这张图中没有出现\n",
    "        else:\n",
    "            ious.append(intersection / union)\n",
    "    # 返回所有类别的 mIoU（排除 nan）\n",
    "    return np.nanmean(ious)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2387491",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model(model, dataloader, num_classes=5, max_samples=10):\n",
    "    model.eval()\n",
    "    total_miou = 0\n",
    "    count = 0\n",
    "\n",
    "    for i, (images, masks) in enumerate(dataloader):\n",
    "        if i >= max_samples:  # 只验证前 max_samples 个样本\n",
    "            break\n",
    "\n",
    "        images = images.cuda()\n",
    "        masks = masks.cuda()\n",
    "\n",
    "        outputs = model(images)  # [B, C, H, W]\n",
    "        preds = torch.argmax(outputs, dim=1)  # [B, H, W]\n",
    "\n",
    "        for b in range(images.size(0)):\n",
    "            miou = calculate_mIoU(preds[b], masks[b], num_classes)\n",
    "            print(f\"Image {count + 1} mIoU: {miou:.4f}\")\n",
    "            total_miou += miou\n",
    "            count += 1\n",
    "\n",
    "    avg_miou = total_miou / count\n",
    "    print(f\"\\n✅ Average mIoU over {count} samples: {avg_miou:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "938b8f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## miou作为验证指标\n",
    "def eval_miou():\n",
    "    # 修改为你的路径\n",
    "    model_path = \"Train_01.pth\"\n",
    "    image_dir = img_path\n",
    "    mask_dir = mask_path\n",
    "    num_classes = 5\n",
    "\n",
    "    # 加载模型\n",
    "    model = SegNet(num_classes=num_classes)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.cuda()\n",
    "\n",
    "    # 数据变换\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # 数据加载\n",
    "    dataset = SegmentationDataset(image_dir, mask_dir, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # 验证模型\n",
    "    evaluate_model(model, dataloader, num_classes=num_classes, max_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e82157ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8511/687239090.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 mIoU: 0.9464\n",
      "Image 2 mIoU: 0.9556\n",
      "Image 3 mIoU: 0.9125\n",
      "Image 4 mIoU: 0.9487\n",
      "Image 5 mIoU: 0.6716\n",
      "Image 6 mIoU: 0.9251\n",
      "Image 7 mIoU: 0.9563\n",
      "Image 8 mIoU: 0.9284\n",
      "Image 9 mIoU: 0.9489\n",
      "Image 10 mIoU: 0.9614\n",
      "Image 11 mIoU: 0.9368\n",
      "Image 12 mIoU: 0.9299\n",
      "Image 13 mIoU: 0.9159\n",
      "Image 14 mIoU: 0.9160\n",
      "Image 15 mIoU: 0.9412\n",
      "Image 16 mIoU: 0.9023\n",
      "Image 17 mIoU: 0.9504\n",
      "Image 18 mIoU: 0.9043\n",
      "Image 19 mIoU: 0.9540\n",
      "Image 20 mIoU: 0.6900\n",
      "Image 21 mIoU: 0.9581\n",
      "Image 22 mIoU: 0.9573\n",
      "Image 23 mIoU: 0.9539\n",
      "Image 24 mIoU: 0.9384\n",
      "Image 25 mIoU: 0.9078\n",
      "Image 26 mIoU: 0.9653\n",
      "Image 27 mIoU: 0.9548\n",
      "Image 28 mIoU: 0.6086\n",
      "Image 29 mIoU: 0.9146\n",
      "Image 30 mIoU: 0.9264\n",
      "Image 31 mIoU: 0.9560\n",
      "Image 32 mIoU: 0.9611\n",
      "Image 33 mIoU: 0.9421\n",
      "Image 34 mIoU: 0.9292\n",
      "Image 35 mIoU: 0.8882\n",
      "Image 36 mIoU: 0.9600\n",
      "Image 37 mIoU: 0.9381\n",
      "Image 38 mIoU: 0.9237\n",
      "Image 39 mIoU: 0.9108\n",
      "Image 40 mIoU: 0.9211\n",
      "Image 41 mIoU: 0.9212\n",
      "Image 42 mIoU: 0.9215\n",
      "Image 43 mIoU: 0.9198\n",
      "Image 44 mIoU: 0.9585\n",
      "Image 45 mIoU: 0.9253\n",
      "Image 46 mIoU: 0.9473\n",
      "Image 47 mIoU: 0.9602\n",
      "Image 48 mIoU: 0.6107\n",
      "Image 49 mIoU: 0.9090\n",
      "Image 50 mIoU: 0.9176\n",
      "Image 51 mIoU: 0.9555\n",
      "Image 52 mIoU: 0.9091\n",
      "Image 53 mIoU: 0.9202\n",
      "Image 54 mIoU: 0.9500\n",
      "Image 55 mIoU: 0.9186\n",
      "Image 56 mIoU: 0.9323\n",
      "Image 57 mIoU: 0.9557\n",
      "Image 58 mIoU: 0.9423\n",
      "Image 59 mIoU: 0.9276\n",
      "Image 60 mIoU: 0.9202\n",
      "Image 61 mIoU: 0.9608\n",
      "Image 62 mIoU: 0.9274\n",
      "Image 63 mIoU: 0.9524\n",
      "Image 64 mIoU: 0.9489\n",
      "Image 65 mIoU: 0.9553\n",
      "Image 66 mIoU: 0.9147\n",
      "Image 67 mIoU: 0.9572\n",
      "Image 68 mIoU: 0.9217\n",
      "Image 69 mIoU: 0.9432\n",
      "Image 70 mIoU: 0.9517\n",
      "Image 71 mIoU: 0.9485\n",
      "Image 72 mIoU: 0.9511\n",
      "Image 73 mIoU: 0.9358\n",
      "Image 74 mIoU: 0.9653\n",
      "Image 75 mIoU: 0.9173\n",
      "Image 76 mIoU: 0.9481\n",
      "Image 77 mIoU: 0.9342\n",
      "Image 78 mIoU: 0.9465\n",
      "Image 79 mIoU: 0.9227\n",
      "Image 80 mIoU: 0.9582\n",
      "Image 81 mIoU: 0.9047\n",
      "Image 82 mIoU: 0.9526\n",
      "Image 83 mIoU: 0.9567\n",
      "Image 84 mIoU: 0.9240\n",
      "Image 85 mIoU: 0.9329\n",
      "Image 86 mIoU: 0.9363\n",
      "Image 87 mIoU: 0.9605\n",
      "Image 88 mIoU: 0.9326\n",
      "Image 89 mIoU: 0.9495\n",
      "Image 90 mIoU: 0.9457\n",
      "Image 91 mIoU: 0.9620\n",
      "Image 92 mIoU: 0.9111\n",
      "Image 93 mIoU: 0.9515\n",
      "Image 94 mIoU: 0.9198\n",
      "Image 95 mIoU: 0.9481\n",
      "Image 96 mIoU: 0.9165\n",
      "Image 97 mIoU: 0.9422\n",
      "Image 98 mIoU: 0.9304\n",
      "Image 99 mIoU: 0.9462\n",
      "Image 100 mIoU: 0.9532\n",
      "Image 101 mIoU: 0.9359\n",
      "Image 102 mIoU: 0.9345\n",
      "Image 103 mIoU: 0.9425\n",
      "Image 104 mIoU: 0.9331\n",
      "Image 105 mIoU: 0.9537\n",
      "Image 106 mIoU: 0.9305\n",
      "Image 107 mIoU: 0.9467\n",
      "Image 108 mIoU: 0.9339\n",
      "Image 109 mIoU: 0.9331\n",
      "Image 110 mIoU: 0.9538\n",
      "Image 111 mIoU: 0.9274\n",
      "Image 112 mIoU: 0.9497\n",
      "Image 113 mIoU: 0.9406\n",
      "Image 114 mIoU: 0.9153\n",
      "Image 115 mIoU: 0.6082\n",
      "Image 116 mIoU: 0.9669\n",
      "Image 117 mIoU: 0.9587\n",
      "Image 118 mIoU: 0.9497\n",
      "Image 119 mIoU: 0.9246\n",
      "Image 120 mIoU: 0.9564\n",
      "Image 121 mIoU: 0.9440\n",
      "Image 122 mIoU: 0.9294\n",
      "Image 123 mIoU: 0.9376\n",
      "Image 124 mIoU: 0.9538\n",
      "Image 125 mIoU: 0.9216\n",
      "Image 126 mIoU: 0.9201\n",
      "Image 127 mIoU: 0.9193\n",
      "Image 128 mIoU: 0.9597\n",
      "Image 129 mIoU: 0.9090\n",
      "Image 130 mIoU: 0.9256\n",
      "Image 131 mIoU: 0.9439\n",
      "Image 132 mIoU: 0.9658\n",
      "Image 133 mIoU: 0.9416\n",
      "Image 134 mIoU: 0.9413\n",
      "Image 135 mIoU: 0.9318\n",
      "Image 136 mIoU: 0.9395\n",
      "Image 137 mIoU: 0.9358\n",
      "Image 138 mIoU: 0.8866\n",
      "Image 139 mIoU: 0.9573\n",
      "Image 140 mIoU: 0.9552\n",
      "Image 141 mIoU: 0.9380\n",
      "Image 142 mIoU: 0.9270\n",
      "Image 143 mIoU: 0.9511\n",
      "Image 144 mIoU: 0.9359\n",
      "Image 145 mIoU: 0.9249\n",
      "Image 146 mIoU: 0.9615\n",
      "Image 147 mIoU: 0.9257\n",
      "Image 148 mIoU: 0.9278\n",
      "Image 149 mIoU: 0.9348\n",
      "Image 150 mIoU: 0.9537\n",
      "Image 151 mIoU: 0.9497\n",
      "Image 152 mIoU: 0.9235\n",
      "Image 153 mIoU: 0.9484\n",
      "Image 154 mIoU: 0.9408\n",
      "Image 155 mIoU: 0.9105\n",
      "Image 156 mIoU: 0.9508\n",
      "Image 157 mIoU: 0.9267\n",
      "Image 158 mIoU: 0.9235\n",
      "Image 159 mIoU: 0.9263\n",
      "Image 160 mIoU: 0.9252\n",
      "Image 161 mIoU: 0.9380\n",
      "Image 162 mIoU: 0.9324\n",
      "Image 163 mIoU: 0.9553\n",
      "Image 164 mIoU: 0.9483\n",
      "Image 165 mIoU: 0.9594\n",
      "Image 166 mIoU: 0.9605\n",
      "Image 167 mIoU: 0.9055\n",
      "Image 168 mIoU: 0.9527\n",
      "Image 169 mIoU: 0.9410\n",
      "Image 170 mIoU: 0.9255\n",
      "Image 171 mIoU: 0.9226\n",
      "Image 172 mIoU: 0.9556\n",
      "Image 173 mIoU: 0.9517\n",
      "Image 174 mIoU: 0.9569\n",
      "Image 175 mIoU: 0.9263\n",
      "Image 176 mIoU: 0.9144\n",
      "Image 177 mIoU: 0.9671\n",
      "Image 178 mIoU: 0.8929\n",
      "Image 179 mIoU: 0.9564\n",
      "Image 180 mIoU: 0.9131\n",
      "Image 181 mIoU: 0.9567\n",
      "Image 182 mIoU: 0.9221\n",
      "Image 183 mIoU: 0.9448\n",
      "Image 184 mIoU: 0.9378\n",
      "Image 185 mIoU: 0.9466\n",
      "Image 186 mIoU: 0.9240\n",
      "Image 187 mIoU: 0.9363\n",
      "Image 188 mIoU: 0.9228\n",
      "Image 189 mIoU: 0.9288\n",
      "Image 190 mIoU: 0.9492\n",
      "Image 191 mIoU: 0.9583\n",
      "Image 192 mIoU: 0.9336\n",
      "Image 193 mIoU: 0.9457\n",
      "Image 194 mIoU: 0.9309\n",
      "Image 195 mIoU: 0.9130\n",
      "Image 196 mIoU: 0.9258\n",
      "Image 197 mIoU: 0.9490\n",
      "Image 198 mIoU: 0.9200\n",
      "Image 199 mIoU: 0.9355\n",
      "Image 200 mIoU: 0.9001\n",
      "Image 201 mIoU: 0.9195\n",
      "Image 202 mIoU: 0.9538\n",
      "Image 203 mIoU: 0.9231\n",
      "Image 204 mIoU: 0.9497\n",
      "Image 205 mIoU: 0.9529\n",
      "Image 206 mIoU: 0.9192\n",
      "Image 207 mIoU: 0.9410\n",
      "Image 208 mIoU: 0.9526\n",
      "Image 209 mIoU: 0.9269\n",
      "Image 210 mIoU: 0.9237\n",
      "Image 211 mIoU: 0.9575\n",
      "Image 212 mIoU: 0.9570\n",
      "Image 213 mIoU: 0.9431\n",
      "Image 214 mIoU: 0.9519\n",
      "Image 215 mIoU: 0.9355\n",
      "Image 216 mIoU: 0.9460\n",
      "Image 217 mIoU: 0.9414\n",
      "Image 218 mIoU: 0.9376\n",
      "Image 219 mIoU: 0.9532\n",
      "Image 220 mIoU: 0.8956\n",
      "Image 221 mIoU: 0.9528\n",
      "Image 222 mIoU: 0.9512\n",
      "Image 223 mIoU: 0.9379\n",
      "Image 224 mIoU: 0.9375\n",
      "Image 225 mIoU: 0.9551\n",
      "Image 226 mIoU: 0.9314\n",
      "Image 227 mIoU: 0.9515\n",
      "Image 228 mIoU: 0.9581\n",
      "Image 229 mIoU: 0.9526\n",
      "Image 230 mIoU: 0.9364\n",
      "Image 231 mIoU: 0.9276\n",
      "Image 232 mIoU: 0.9566\n",
      "Image 233 mIoU: 0.9483\n",
      "Image 234 mIoU: 0.9404\n",
      "Image 235 mIoU: 0.9286\n",
      "Image 236 mIoU: 0.9361\n",
      "Image 237 mIoU: 0.9411\n",
      "Image 238 mIoU: 0.9137\n",
      "Image 239 mIoU: 0.9244\n",
      "Image 240 mIoU: 0.9507\n",
      "Image 241 mIoU: 0.9395\n",
      "Image 242 mIoU: 0.9433\n",
      "Image 243 mIoU: 0.9497\n",
      "Image 244 mIoU: 0.8962\n",
      "Image 245 mIoU: 0.8966\n",
      "Image 246 mIoU: 0.9559\n",
      "Image 247 mIoU: 0.9509\n",
      "Image 248 mIoU: 0.9372\n",
      "Image 249 mIoU: 0.9359\n",
      "Image 250 mIoU: 0.9540\n",
      "Image 251 mIoU: 0.9190\n",
      "Image 252 mIoU: 0.9211\n",
      "Image 253 mIoU: 0.9395\n",
      "Image 254 mIoU: 0.9408\n",
      "Image 255 mIoU: 0.9101\n",
      "Image 256 mIoU: 0.9435\n",
      "Image 257 mIoU: 0.9286\n",
      "Image 258 mIoU: 0.9398\n",
      "Image 259 mIoU: 0.9253\n",
      "Image 260 mIoU: 0.9327\n",
      "Image 261 mIoU: 0.9445\n",
      "Image 262 mIoU: 0.9503\n",
      "Image 263 mIoU: 0.9241\n",
      "Image 264 mIoU: 0.9155\n",
      "Image 265 mIoU: 0.9388\n",
      "Image 266 mIoU: 0.9379\n",
      "Image 267 mIoU: 0.9540\n",
      "Image 268 mIoU: 0.9334\n",
      "Image 269 mIoU: 0.9148\n",
      "Image 270 mIoU: 0.9509\n",
      "Image 271 mIoU: 0.9295\n",
      "Image 272 mIoU: 0.9223\n",
      "Image 273 mIoU: 0.9329\n",
      "Image 274 mIoU: 0.9310\n",
      "Image 275 mIoU: 0.9266\n",
      "Image 276 mIoU: 0.9348\n",
      "Image 277 mIoU: 0.9546\n",
      "Image 278 mIoU: 0.9201\n",
      "Image 279 mIoU: 0.9610\n",
      "Image 280 mIoU: 0.9392\n",
      "Image 281 mIoU: 0.9573\n",
      "Image 282 mIoU: 0.9549\n",
      "Image 283 mIoU: 0.9650\n",
      "Image 284 mIoU: 0.9104\n",
      "Image 285 mIoU: 0.9324\n",
      "Image 286 mIoU: 0.9499\n",
      "Image 287 mIoU: 0.8940\n",
      "Image 288 mIoU: 0.9271\n",
      "Image 289 mIoU: 0.9569\n",
      "Image 290 mIoU: 0.9317\n",
      "Image 291 mIoU: 0.9504\n",
      "Image 292 mIoU: 0.9147\n",
      "Image 293 mIoU: 0.9486\n",
      "Image 294 mIoU: 0.9619\n",
      "Image 295 mIoU: 0.8975\n",
      "Image 296 mIoU: 0.9512\n",
      "Image 297 mIoU: 0.9231\n",
      "Image 298 mIoU: 0.9492\n",
      "Image 299 mIoU: 0.9391\n",
      "Image 300 mIoU: 0.9289\n",
      "Image 301 mIoU: 0.9498\n",
      "Image 302 mIoU: 0.9191\n",
      "Image 303 mIoU: 0.9060\n",
      "Image 304 mIoU: 0.9201\n",
      "Image 305 mIoU: 0.9544\n",
      "Image 306 mIoU: 0.9107\n",
      "Image 307 mIoU: 0.9269\n",
      "Image 308 mIoU: 0.9271\n",
      "Image 309 mIoU: 0.9611\n",
      "Image 310 mIoU: 0.9189\n",
      "Image 311 mIoU: 0.9415\n",
      "Image 312 mIoU: 0.9532\n",
      "Image 313 mIoU: 0.9243\n",
      "Image 314 mIoU: 0.9561\n",
      "Image 315 mIoU: 0.9479\n",
      "Image 316 mIoU: 0.9546\n",
      "Image 317 mIoU: 0.9371\n",
      "Image 318 mIoU: 0.9035\n",
      "Image 319 mIoU: 0.9354\n",
      "Image 320 mIoU: 0.9133\n",
      "Image 321 mIoU: 0.9448\n",
      "Image 322 mIoU: 0.9533\n",
      "Image 323 mIoU: 0.9289\n",
      "Image 324 mIoU: 0.9511\n",
      "Image 325 mIoU: 0.9546\n",
      "Image 326 mIoU: 0.9366\n",
      "Image 327 mIoU: 0.9384\n",
      "Image 328 mIoU: 0.9301\n",
      "Image 329 mIoU: 0.9524\n",
      "Image 330 mIoU: 0.9565\n",
      "Image 331 mIoU: 0.9384\n",
      "Image 332 mIoU: 0.9013\n",
      "Image 333 mIoU: 0.9569\n",
      "Image 334 mIoU: 0.9525\n",
      "Image 335 mIoU: 0.9215\n",
      "Image 336 mIoU: 0.9442\n",
      "Image 337 mIoU: 0.9480\n",
      "Image 338 mIoU: 0.9516\n",
      "Image 339 mIoU: 0.9570\n",
      "Image 340 mIoU: 0.9419\n",
      "Image 341 mIoU: 0.9258\n",
      "Image 342 mIoU: 0.9373\n",
      "Image 343 mIoU: 0.9316\n",
      "Image 344 mIoU: 0.9560\n",
      "Image 345 mIoU: 0.9611\n",
      "Image 346 mIoU: 0.9572\n",
      "Image 347 mIoU: 0.9361\n",
      "Image 348 mIoU: 0.9461\n",
      "Image 349 mIoU: 0.9412\n",
      "Image 350 mIoU: 0.9593\n",
      "Image 351 mIoU: 0.9292\n",
      "Image 352 mIoU: 0.9055\n",
      "Image 353 mIoU: 0.9147\n",
      "Image 354 mIoU: 0.9563\n",
      "Image 355 mIoU: 0.9332\n",
      "Image 356 mIoU: 0.9526\n",
      "Image 357 mIoU: 0.9513\n",
      "Image 358 mIoU: 0.9419\n",
      "Image 359 mIoU: 0.9572\n",
      "Image 360 mIoU: 0.9502\n",
      "Image 361 mIoU: 0.9428\n",
      "Image 362 mIoU: 0.9543\n",
      "Image 363 mIoU: 0.9345\n",
      "Image 364 mIoU: 0.9582\n",
      "Image 365 mIoU: 0.8969\n",
      "Image 366 mIoU: 0.9498\n",
      "Image 367 mIoU: 0.9549\n",
      "Image 368 mIoU: 0.9349\n",
      "Image 369 mIoU: 0.9516\n",
      "Image 370 mIoU: 0.9575\n",
      "Image 371 mIoU: 0.9344\n",
      "Image 372 mIoU: 0.9233\n",
      "Image 373 mIoU: 0.9119\n",
      "Image 374 mIoU: 0.9439\n",
      "Image 375 mIoU: 0.9598\n",
      "Image 376 mIoU: 0.9562\n",
      "Image 377 mIoU: 0.9243\n",
      "Image 378 mIoU: 0.9275\n",
      "Image 379 mIoU: 0.9520\n",
      "Image 380 mIoU: 0.9366\n",
      "Image 381 mIoU: 0.9200\n",
      "Image 382 mIoU: 0.9308\n",
      "Image 383 mIoU: 0.9421\n",
      "Image 384 mIoU: 0.9338\n",
      "Image 385 mIoU: 0.9603\n",
      "Image 386 mIoU: 0.9354\n",
      "Image 387 mIoU: 0.9553\n",
      "Image 388 mIoU: 0.9517\n",
      "Image 389 mIoU: 0.9580\n",
      "Image 390 mIoU: 0.9553\n",
      "Image 391 mIoU: 0.9360\n",
      "Image 392 mIoU: 0.9076\n",
      "Image 393 mIoU: 0.9081\n",
      "Image 394 mIoU: 0.9110\n",
      "Image 395 mIoU: 0.9490\n",
      "Image 396 mIoU: 0.9544\n",
      "Image 397 mIoU: 0.8926\n",
      "Image 398 mIoU: 0.9198\n",
      "Image 399 mIoU: 0.9203\n",
      "Image 400 mIoU: 0.9076\n",
      "Image 401 mIoU: 0.9328\n",
      "Image 402 mIoU: 0.9341\n",
      "Image 403 mIoU: 0.9112\n",
      "Image 404 mIoU: 0.9265\n",
      "Image 405 mIoU: 0.9485\n",
      "Image 406 mIoU: 0.9543\n",
      "Image 407 mIoU: 0.9302\n",
      "Image 408 mIoU: 0.9211\n",
      "Image 409 mIoU: 0.9097\n",
      "Image 410 mIoU: 0.9417\n",
      "Image 411 mIoU: 0.9446\n",
      "Image 412 mIoU: 0.9333\n",
      "Image 413 mIoU: 0.9464\n",
      "Image 414 mIoU: 0.9557\n",
      "Image 415 mIoU: 0.9571\n",
      "Image 416 mIoU: 0.9273\n",
      "Image 417 mIoU: 0.9384\n",
      "Image 418 mIoU: 0.9612\n",
      "Image 419 mIoU: 0.9203\n",
      "Image 420 mIoU: 0.9163\n",
      "Image 421 mIoU: 0.9254\n",
      "Image 422 mIoU: 0.9360\n",
      "Image 423 mIoU: 0.9254\n",
      "Image 424 mIoU: 0.9565\n",
      "Image 425 mIoU: 0.9455\n",
      "Image 426 mIoU: 0.9549\n",
      "Image 427 mIoU: 0.9233\n",
      "Image 428 mIoU: 0.9556\n",
      "Image 429 mIoU: 0.9494\n",
      "Image 430 mIoU: 0.9124\n",
      "Image 431 mIoU: 0.9438\n",
      "Image 432 mIoU: 0.9342\n",
      "Image 433 mIoU: 0.9344\n",
      "Image 434 mIoU: 0.6896\n",
      "Image 435 mIoU: 0.9560\n",
      "Image 436 mIoU: 0.9089\n",
      "Image 437 mIoU: 0.9531\n",
      "Image 438 mIoU: 0.9251\n",
      "Image 439 mIoU: 0.9524\n",
      "Image 440 mIoU: 0.9254\n",
      "Image 441 mIoU: 0.9173\n",
      "Image 442 mIoU: 0.9479\n",
      "Image 443 mIoU: 0.9310\n",
      "Image 444 mIoU: 0.9458\n",
      "Image 445 mIoU: 0.9147\n",
      "Image 446 mIoU: 0.9610\n",
      "Image 447 mIoU: 0.9468\n",
      "Image 448 mIoU: 0.9245\n",
      "Image 449 mIoU: 0.9476\n",
      "Image 450 mIoU: 0.9317\n",
      "Image 451 mIoU: 0.9190\n",
      "Image 452 mIoU: 0.9253\n",
      "Image 453 mIoU: 0.9549\n",
      "Image 454 mIoU: 0.9020\n",
      "Image 455 mIoU: 0.9555\n",
      "Image 456 mIoU: 0.9439\n",
      "Image 457 mIoU: 0.9529\n",
      "Image 458 mIoU: 0.9463\n",
      "Image 459 mIoU: 0.9498\n",
      "Image 460 mIoU: 0.9372\n",
      "Image 461 mIoU: 0.9018\n",
      "Image 462 mIoU: 0.9473\n",
      "Image 463 mIoU: 0.9328\n",
      "Image 464 mIoU: 0.9202\n",
      "Image 465 mIoU: 0.9475\n",
      "Image 466 mIoU: 0.9306\n",
      "Image 467 mIoU: 0.9310\n",
      "Image 468 mIoU: 0.9548\n",
      "Image 469 mIoU: 0.9557\n",
      "Image 470 mIoU: 0.9574\n",
      "Image 471 mIoU: 0.9500\n",
      "Image 472 mIoU: 0.9047\n",
      "Image 473 mIoU: 0.9530\n",
      "Image 474 mIoU: 0.9485\n",
      "Image 475 mIoU: 0.9593\n",
      "Image 476 mIoU: 0.9318\n",
      "Image 477 mIoU: 0.9409\n",
      "Image 478 mIoU: 0.9162\n",
      "Image 479 mIoU: 0.9349\n",
      "Image 480 mIoU: 0.8987\n",
      "Image 481 mIoU: 0.9374\n",
      "Image 482 mIoU: 0.9067\n",
      "Image 483 mIoU: 0.9245\n",
      "Image 484 mIoU: 0.9499\n",
      "Image 485 mIoU: 0.9612\n",
      "Image 486 mIoU: 0.9171\n",
      "Image 487 mIoU: 0.9043\n",
      "Image 488 mIoU: 0.6796\n",
      "Image 489 mIoU: 0.9512\n",
      "Image 490 mIoU: 0.9339\n",
      "Image 491 mIoU: 0.9562\n",
      "Image 492 mIoU: 0.9600\n",
      "Image 493 mIoU: 0.9413\n",
      "Image 494 mIoU: 0.9151\n",
      "Image 495 mIoU: 0.9492\n",
      "Image 496 mIoU: 0.9346\n",
      "Image 497 mIoU: 0.9629\n",
      "Image 498 mIoU: 0.9248\n",
      "Image 499 mIoU: 0.9549\n",
      "Image 500 mIoU: 0.9527\n",
      "Image 501 mIoU: 0.9290\n",
      "Image 502 mIoU: 0.9478\n",
      "Image 503 mIoU: 0.9526\n",
      "Image 504 mIoU: 0.9551\n",
      "Image 505 mIoU: 0.9293\n",
      "Image 506 mIoU: 0.9373\n",
      "Image 507 mIoU: 0.9432\n",
      "Image 508 mIoU: 0.9282\n",
      "Image 509 mIoU: 0.9107\n",
      "Image 510 mIoU: 0.9413\n",
      "Image 511 mIoU: 0.9294\n",
      "Image 512 mIoU: 0.9582\n",
      "Image 513 mIoU: 0.9557\n",
      "Image 514 mIoU: 0.9558\n",
      "Image 515 mIoU: 0.9541\n",
      "Image 516 mIoU: 0.9234\n",
      "Image 517 mIoU: 0.9591\n",
      "Image 518 mIoU: 0.9220\n",
      "Image 519 mIoU: 0.9533\n",
      "Image 520 mIoU: 0.9334\n",
      "Image 521 mIoU: 0.9489\n",
      "Image 522 mIoU: 0.9548\n",
      "Image 523 mIoU: 0.9090\n",
      "Image 524 mIoU: 0.9536\n",
      "Image 525 mIoU: 0.9328\n",
      "Image 526 mIoU: 0.9534\n",
      "Image 527 mIoU: 0.9298\n",
      "Image 528 mIoU: 0.9493\n",
      "Image 529 mIoU: 0.9443\n",
      "Image 530 mIoU: 0.9253\n",
      "Image 531 mIoU: 0.9381\n",
      "Image 532 mIoU: 0.9318\n",
      "Image 533 mIoU: 0.9522\n",
      "Image 534 mIoU: 0.9540\n",
      "Image 535 mIoU: 0.9459\n",
      "Image 536 mIoU: 0.9340\n",
      "Image 537 mIoU: 0.9138\n",
      "Image 538 mIoU: 0.9446\n",
      "Image 539 mIoU: 0.9211\n",
      "Image 540 mIoU: 0.9195\n",
      "Image 541 mIoU: 0.9582\n",
      "Image 542 mIoU: 0.9275\n",
      "Image 543 mIoU: 0.9538\n",
      "Image 544 mIoU: 0.9375\n",
      "Image 545 mIoU: 0.9246\n",
      "Image 546 mIoU: 0.9525\n",
      "Image 547 mIoU: 0.9355\n",
      "Image 548 mIoU: 0.9240\n",
      "Image 549 mIoU: 0.9641\n",
      "Image 550 mIoU: 0.8925\n",
      "Image 551 mIoU: 0.9466\n",
      "Image 552 mIoU: 0.9537\n",
      "Image 553 mIoU: 0.9618\n",
      "Image 554 mIoU: 0.9469\n",
      "Image 555 mIoU: 0.9582\n",
      "Image 556 mIoU: 0.9282\n",
      "Image 557 mIoU: 0.9206\n",
      "Image 558 mIoU: 0.9179\n",
      "Image 559 mIoU: 0.9648\n",
      "Image 560 mIoU: 0.9589\n",
      "Image 561 mIoU: 0.9311\n",
      "Image 562 mIoU: 0.9514\n",
      "Image 563 mIoU: 0.6031\n",
      "Image 564 mIoU: 0.9122\n",
      "Image 565 mIoU: 0.9159\n",
      "Image 566 mIoU: 0.9153\n",
      "Image 567 mIoU: 0.9369\n",
      "Image 568 mIoU: 0.9617\n",
      "Image 569 mIoU: 0.9515\n",
      "Image 570 mIoU: 0.9258\n",
      "Image 571 mIoU: 0.9216\n",
      "Image 572 mIoU: 0.8956\n",
      "Image 573 mIoU: 0.9584\n",
      "Image 574 mIoU: 0.9240\n",
      "Image 575 mIoU: 0.9364\n",
      "Image 576 mIoU: 0.9588\n",
      "Image 577 mIoU: 0.9511\n",
      "Image 578 mIoU: 0.9498\n",
      "Image 579 mIoU: 0.9286\n",
      "Image 580 mIoU: 0.9239\n",
      "Image 581 mIoU: 0.9289\n",
      "Image 582 mIoU: 0.9320\n",
      "Image 583 mIoU: 0.9538\n",
      "Image 584 mIoU: 0.9239\n",
      "Image 585 mIoU: 0.9475\n",
      "Image 586 mIoU: 0.9598\n",
      "Image 587 mIoU: 0.9572\n",
      "Image 588 mIoU: 0.9295\n",
      "Image 589 mIoU: 0.9506\n",
      "Image 590 mIoU: 0.9055\n",
      "Image 591 mIoU: 0.9451\n",
      "Image 592 mIoU: 0.9529\n",
      "Image 593 mIoU: 0.9563\n",
      "Image 594 mIoU: 0.9517\n",
      "Image 595 mIoU: 0.9518\n",
      "Image 596 mIoU: 0.9569\n",
      "Image 597 mIoU: 0.9283\n",
      "Image 598 mIoU: 0.9560\n",
      "Image 599 mIoU: 0.9530\n",
      "Image 600 mIoU: 0.6034\n",
      "Image 601 mIoU: 0.9379\n",
      "Image 602 mIoU: 0.9358\n",
      "Image 603 mIoU: 0.9552\n",
      "Image 604 mIoU: 0.9295\n",
      "Image 605 mIoU: 0.9121\n",
      "Image 606 mIoU: 0.9590\n",
      "Image 607 mIoU: 0.9466\n",
      "Image 608 mIoU: 0.9517\n",
      "Image 609 mIoU: 0.9526\n",
      "Image 610 mIoU: 0.9554\n",
      "Image 611 mIoU: 0.9282\n",
      "Image 612 mIoU: 0.9545\n",
      "Image 613 mIoU: 0.9306\n",
      "Image 614 mIoU: 0.9217\n",
      "Image 615 mIoU: 0.9507\n",
      "Image 616 mIoU: 0.9461\n",
      "Image 617 mIoU: 0.9505\n",
      "Image 618 mIoU: 0.9368\n",
      "Image 619 mIoU: 0.9227\n",
      "Image 620 mIoU: 0.9187\n",
      "Image 621 mIoU: 0.9037\n",
      "Image 622 mIoU: 0.9510\n",
      "Image 623 mIoU: 0.9302\n",
      "Image 624 mIoU: 0.9489\n",
      "Image 625 mIoU: 0.9477\n",
      "Image 626 mIoU: 0.9352\n",
      "Image 627 mIoU: 0.9541\n",
      "Image 628 mIoU: 0.9121\n",
      "Image 629 mIoU: 0.9512\n",
      "Image 630 mIoU: 0.9575\n",
      "Image 631 mIoU: 0.9223\n",
      "Image 632 mIoU: 0.9201\n",
      "Image 633 mIoU: 0.9469\n",
      "Image 634 mIoU: 0.9068\n",
      "Image 635 mIoU: 0.9364\n",
      "Image 636 mIoU: 0.9259\n",
      "Image 637 mIoU: 0.9478\n",
      "Image 638 mIoU: 0.9304\n",
      "Image 639 mIoU: 0.9418\n",
      "Image 640 mIoU: 0.9632\n",
      "Image 641 mIoU: 0.9485\n",
      "Image 642 mIoU: 0.9380\n",
      "Image 643 mIoU: 0.9122\n",
      "Image 644 mIoU: 0.9503\n",
      "Image 645 mIoU: 0.9336\n",
      "Image 646 mIoU: 0.9609\n",
      "Image 647 mIoU: 0.9202\n",
      "Image 648 mIoU: 0.9344\n",
      "Image 649 mIoU: 0.9243\n",
      "Image 650 mIoU: 0.9245\n",
      "Image 651 mIoU: 0.9527\n",
      "Image 652 mIoU: 0.9599\n",
      "Image 653 mIoU: 0.9537\n",
      "Image 654 mIoU: 0.9621\n",
      "Image 655 mIoU: 0.9543\n",
      "Image 656 mIoU: 0.8994\n",
      "Image 657 mIoU: 0.9600\n",
      "Image 658 mIoU: 0.9563\n",
      "Image 659 mIoU: 0.9417\n",
      "Image 660 mIoU: 0.9568\n",
      "Image 661 mIoU: 0.9478\n",
      "Image 662 mIoU: 0.9235\n",
      "Image 663 mIoU: 0.9542\n",
      "Image 664 mIoU: 0.9584\n",
      "Image 665 mIoU: 0.9451\n",
      "Image 666 mIoU: 0.9261\n",
      "Image 667 mIoU: 0.9143\n",
      "Image 668 mIoU: 0.9236\n",
      "Image 669 mIoU: 0.9585\n",
      "Image 670 mIoU: 0.9226\n",
      "Image 671 mIoU: 0.9519\n",
      "Image 672 mIoU: 0.9109\n",
      "Image 673 mIoU: 0.9562\n",
      "Image 674 mIoU: 0.9308\n",
      "Image 675 mIoU: 0.9401\n",
      "Image 676 mIoU: 0.9574\n",
      "Image 677 mIoU: 0.9013\n",
      "Image 678 mIoU: 0.9375\n",
      "Image 679 mIoU: 0.9554\n",
      "Image 680 mIoU: 0.9578\n",
      "Image 681 mIoU: 0.9226\n",
      "Image 682 mIoU: 0.9592\n",
      "Image 683 mIoU: 0.9355\n",
      "Image 684 mIoU: 0.9527\n",
      "Image 685 mIoU: 0.9523\n",
      "Image 686 mIoU: 0.9285\n",
      "Image 687 mIoU: 0.9330\n",
      "Image 688 mIoU: 0.9163\n",
      "Image 689 mIoU: 0.9309\n",
      "Image 690 mIoU: 0.9522\n",
      "Image 691 mIoU: 0.9515\n",
      "Image 692 mIoU: 0.9172\n",
      "Image 693 mIoU: 0.9197\n",
      "Image 694 mIoU: 0.9437\n",
      "Image 695 mIoU: 0.9019\n",
      "Image 696 mIoU: 0.9284\n",
      "Image 697 mIoU: 0.9502\n",
      "Image 698 mIoU: 0.9544\n",
      "Image 699 mIoU: 0.9468\n",
      "Image 700 mIoU: 0.9324\n",
      "Image 701 mIoU: 0.9350\n",
      "Image 702 mIoU: 0.9231\n",
      "Image 703 mIoU: 0.9221\n",
      "Image 704 mIoU: 0.9582\n",
      "Image 705 mIoU: 0.9542\n",
      "Image 706 mIoU: 0.9561\n",
      "Image 707 mIoU: 0.9399\n",
      "Image 708 mIoU: 0.9392\n",
      "Image 709 mIoU: 0.9438\n",
      "Image 710 mIoU: 0.9141\n",
      "Image 711 mIoU: 0.9226\n",
      "Image 712 mIoU: 0.9487\n",
      "Image 713 mIoU: 0.9594\n",
      "Image 714 mIoU: 0.9542\n",
      "Image 715 mIoU: 0.9558\n",
      "Image 716 mIoU: 0.9400\n",
      "Image 717 mIoU: 0.9288\n",
      "Image 718 mIoU: 0.9276\n",
      "Image 719 mIoU: 0.9585\n",
      "Image 720 mIoU: 0.9580\n",
      "Image 721 mIoU: 0.9436\n",
      "Image 722 mIoU: 0.9295\n",
      "Image 723 mIoU: 0.9130\n",
      "Image 724 mIoU: 0.9349\n",
      "Image 725 mIoU: 0.9270\n",
      "Image 726 mIoU: 0.9432\n",
      "Image 727 mIoU: 0.9598\n",
      "Image 728 mIoU: 0.9295\n",
      "Image 729 mIoU: 0.9540\n",
      "Image 730 mIoU: 0.9209\n",
      "Image 731 mIoU: 0.9649\n",
      "Image 732 mIoU: 0.9347\n",
      "Image 733 mIoU: 0.9171\n",
      "Image 734 mIoU: 0.9645\n",
      "Image 735 mIoU: 0.9254\n",
      "Image 736 mIoU: 0.9183\n",
      "Image 737 mIoU: 0.9281\n",
      "Image 738 mIoU: 0.9478\n",
      "Image 739 mIoU: 0.9493\n",
      "Image 740 mIoU: 0.9494\n",
      "Image 741 mIoU: 0.9588\n",
      "Image 742 mIoU: 0.9622\n",
      "Image 743 mIoU: 0.9573\n",
      "Image 744 mIoU: 0.9357\n",
      "Image 745 mIoU: 0.9504\n",
      "Image 746 mIoU: 0.9540\n",
      "Image 747 mIoU: 0.9202\n",
      "Image 748 mIoU: 0.9262\n",
      "Image 749 mIoU: 0.9344\n",
      "Image 750 mIoU: 0.9303\n",
      "Image 751 mIoU: 0.9118\n",
      "Image 752 mIoU: 0.9289\n",
      "Image 753 mIoU: 0.9614\n",
      "Image 754 mIoU: 0.9560\n",
      "Image 755 mIoU: 0.9337\n",
      "Image 756 mIoU: 0.9397\n",
      "Image 757 mIoU: 0.9535\n",
      "Image 758 mIoU: 0.9602\n",
      "Image 759 mIoU: 0.9163\n",
      "Image 760 mIoU: 0.9585\n",
      "Image 761 mIoU: 0.9514\n",
      "Image 762 mIoU: 0.9607\n",
      "Image 763 mIoU: 0.9458\n",
      "Image 764 mIoU: 0.9158\n",
      "Image 765 mIoU: 0.9540\n",
      "Image 766 mIoU: 0.9537\n",
      "Image 767 mIoU: 0.9610\n",
      "Image 768 mIoU: 0.9172\n",
      "Image 769 mIoU: 0.9471\n",
      "Image 770 mIoU: 0.9327\n",
      "Image 771 mIoU: 0.9561\n",
      "Image 772 mIoU: 0.9134\n",
      "Image 773 mIoU: 0.9569\n",
      "Image 774 mIoU: 0.9088\n",
      "Image 775 mIoU: 0.9155\n",
      "Image 776 mIoU: 0.9353\n",
      "Image 777 mIoU: 0.9618\n",
      "Image 778 mIoU: 0.9268\n",
      "Image 779 mIoU: 0.9532\n",
      "Image 780 mIoU: 0.9135\n",
      "Image 781 mIoU: 0.9561\n",
      "Image 782 mIoU: 0.9584\n",
      "Image 783 mIoU: 0.9172\n",
      "Image 784 mIoU: 0.9366\n",
      "Image 785 mIoU: 0.9106\n",
      "Image 786 mIoU: 0.9221\n",
      "Image 787 mIoU: 0.9486\n",
      "Image 788 mIoU: 0.9492\n",
      "Image 789 mIoU: 0.9417\n",
      "Image 790 mIoU: 0.9605\n",
      "Image 791 mIoU: 0.9252\n",
      "Image 792 mIoU: 0.9599\n",
      "Image 793 mIoU: 0.9499\n",
      "Image 794 mIoU: 0.9314\n",
      "Image 795 mIoU: 0.9533\n",
      "Image 796 mIoU: 0.9264\n",
      "Image 797 mIoU: 0.9225\n",
      "Image 798 mIoU: 0.9461\n",
      "Image 799 mIoU: 0.9216\n",
      "Image 800 mIoU: 0.9499\n",
      "Image 801 mIoU: 0.9207\n",
      "Image 802 mIoU: 0.9290\n",
      "Image 803 mIoU: 0.9336\n",
      "Image 804 mIoU: 0.9548\n",
      "Image 805 mIoU: 0.9522\n",
      "Image 806 mIoU: 0.9099\n",
      "Image 807 mIoU: 0.9338\n",
      "Image 808 mIoU: 0.9523\n",
      "Image 809 mIoU: 0.9573\n",
      "Image 810 mIoU: 0.9146\n",
      "Image 811 mIoU: 0.9087\n",
      "Image 812 mIoU: 0.9594\n",
      "Image 813 mIoU: 0.9538\n",
      "Image 814 mIoU: 0.9374\n",
      "Image 815 mIoU: 0.9529\n",
      "Image 816 mIoU: 0.9568\n",
      "Image 817 mIoU: 0.6846\n",
      "Image 818 mIoU: 0.9242\n",
      "Image 819 mIoU: 0.9087\n",
      "Image 820 mIoU: 0.9279\n",
      "Image 821 mIoU: 0.9547\n",
      "Image 822 mIoU: 0.9574\n",
      "Image 823 mIoU: 0.9582\n",
      "Image 824 mIoU: 0.9592\n",
      "Image 825 mIoU: 0.9189\n",
      "Image 826 mIoU: 0.9572\n",
      "Image 827 mIoU: 0.9517\n",
      "Image 828 mIoU: 0.9484\n",
      "Image 829 mIoU: 0.9485\n",
      "Image 830 mIoU: 0.9398\n",
      "Image 831 mIoU: 0.9342\n",
      "Image 832 mIoU: 0.9525\n",
      "Image 833 mIoU: 0.9584\n",
      "Image 834 mIoU: 0.9653\n",
      "Image 835 mIoU: 0.9446\n",
      "Image 836 mIoU: 0.9593\n",
      "Image 837 mIoU: 0.9488\n",
      "Image 838 mIoU: 0.9524\n",
      "Image 839 mIoU: 0.9254\n",
      "Image 840 mIoU: 0.9261\n",
      "Image 841 mIoU: 0.9485\n",
      "Image 842 mIoU: 0.9445\n",
      "Image 843 mIoU: 0.9427\n",
      "Image 844 mIoU: 0.9322\n",
      "Image 845 mIoU: 0.9254\n",
      "Image 846 mIoU: 0.9322\n",
      "Image 847 mIoU: 0.9510\n",
      "Image 848 mIoU: 0.9464\n",
      "Image 849 mIoU: 0.9338\n",
      "Image 850 mIoU: 0.9558\n",
      "Image 851 mIoU: 0.9412\n",
      "Image 852 mIoU: 0.9295\n",
      "Image 853 mIoU: 0.9491\n",
      "Image 854 mIoU: 0.9522\n",
      "Image 855 mIoU: 0.9519\n",
      "Image 856 mIoU: 0.9146\n",
      "Image 857 mIoU: 0.9268\n",
      "Image 858 mIoU: 0.9605\n",
      "Image 859 mIoU: 0.9564\n",
      "Image 860 mIoU: 0.9305\n",
      "Image 861 mIoU: 0.9277\n",
      "Image 862 mIoU: 0.9189\n",
      "Image 863 mIoU: 0.9541\n",
      "Image 864 mIoU: 0.9439\n",
      "Image 865 mIoU: 0.9621\n",
      "Image 866 mIoU: 0.9584\n",
      "Image 867 mIoU: 0.9336\n",
      "Image 868 mIoU: 0.9573\n",
      "Image 869 mIoU: 0.9561\n",
      "Image 870 mIoU: 0.9286\n",
      "Image 871 mIoU: 0.9529\n",
      "Image 872 mIoU: 0.9536\n",
      "Image 873 mIoU: 0.8990\n",
      "Image 874 mIoU: 0.9186\n",
      "Image 875 mIoU: 0.9470\n",
      "Image 876 mIoU: 0.9076\n",
      "Image 877 mIoU: 0.9244\n",
      "Image 878 mIoU: 0.9295\n",
      "Image 879 mIoU: 0.8850\n",
      "Image 880 mIoU: 0.9433\n",
      "Image 881 mIoU: 0.9581\n",
      "Image 882 mIoU: 0.9247\n",
      "Image 883 mIoU: 0.9589\n",
      "Image 884 mIoU: 0.9187\n",
      "Image 885 mIoU: 0.9545\n",
      "Image 886 mIoU: 0.9567\n",
      "Image 887 mIoU: 0.9327\n",
      "Image 888 mIoU: 0.9266\n",
      "Image 889 mIoU: 0.9333\n",
      "Image 890 mIoU: 0.9392\n",
      "Image 891 mIoU: 0.9550\n",
      "Image 892 mIoU: 0.9087\n",
      "Image 893 mIoU: 0.9550\n",
      "Image 894 mIoU: 0.9568\n",
      "Image 895 mIoU: 0.9197\n",
      "Image 896 mIoU: 0.9560\n",
      "Image 897 mIoU: 0.9547\n",
      "Image 898 mIoU: 0.9146\n",
      "Image 899 mIoU: 0.9522\n",
      "Image 900 mIoU: 0.9363\n",
      "Image 901 mIoU: 0.9325\n",
      "Image 902 mIoU: 0.9552\n",
      "Image 903 mIoU: 0.9343\n",
      "Image 904 mIoU: 0.9461\n",
      "Image 905 mIoU: 0.9560\n",
      "Image 906 mIoU: 0.9369\n",
      "Image 907 mIoU: 0.9634\n",
      "Image 908 mIoU: 0.9413\n",
      "Image 909 mIoU: 0.9182\n",
      "Image 910 mIoU: 0.9118\n",
      "Image 911 mIoU: 0.9369\n",
      "Image 912 mIoU: 0.9489\n",
      "Image 913 mIoU: 0.9479\n",
      "Image 914 mIoU: 0.9308\n",
      "Image 915 mIoU: 0.9278\n",
      "Image 916 mIoU: 0.6926\n",
      "Image 917 mIoU: 0.9473\n",
      "Image 918 mIoU: 0.9104\n",
      "Image 919 mIoU: 0.9118\n",
      "Image 920 mIoU: 0.9306\n",
      "Image 921 mIoU: 0.9387\n",
      "Image 922 mIoU: 0.9261\n",
      "Image 923 mIoU: 0.9348\n",
      "Image 924 mIoU: 0.9535\n",
      "Image 925 mIoU: 0.9104\n",
      "Image 926 mIoU: 0.9519\n",
      "Image 927 mIoU: 0.9576\n",
      "Image 928 mIoU: 0.9251\n",
      "Image 929 mIoU: 0.9017\n",
      "Image 930 mIoU: 0.9286\n",
      "Image 931 mIoU: 0.9547\n",
      "Image 932 mIoU: 0.9102\n",
      "Image 933 mIoU: 0.6898\n",
      "Image 934 mIoU: 0.6897\n",
      "Image 935 mIoU: 0.9434\n",
      "Image 936 mIoU: 0.9492\n",
      "Image 937 mIoU: 0.9332\n",
      "Image 938 mIoU: 0.9257\n",
      "Image 939 mIoU: 0.9166\n",
      "Image 940 mIoU: 0.9400\n",
      "Image 941 mIoU: 0.9286\n",
      "Image 942 mIoU: 0.9239\n",
      "Image 943 mIoU: 0.9371\n",
      "Image 944 mIoU: 0.9351\n",
      "Image 945 mIoU: 0.9527\n",
      "Image 946 mIoU: 0.9413\n",
      "Image 947 mIoU: 0.9654\n",
      "Image 948 mIoU: 0.9573\n",
      "Image 949 mIoU: 0.9503\n",
      "Image 950 mIoU: 0.9375\n",
      "Image 951 mIoU: 0.9543\n",
      "Image 952 mIoU: 0.9575\n",
      "Image 953 mIoU: 0.9348\n",
      "Image 954 mIoU: 0.9581\n",
      "Image 955 mIoU: 0.9345\n",
      "Image 956 mIoU: 0.9268\n",
      "Image 957 mIoU: 0.9322\n",
      "Image 958 mIoU: 0.9509\n",
      "Image 959 mIoU: 0.9369\n",
      "Image 960 mIoU: 0.9549\n",
      "Image 961 mIoU: 0.9333\n",
      "Image 962 mIoU: 0.9534\n",
      "Image 963 mIoU: 0.9239\n",
      "Image 964 mIoU: 0.9203\n",
      "Image 965 mIoU: 0.9177\n",
      "Image 966 mIoU: 0.9276\n",
      "Image 967 mIoU: 0.9611\n",
      "Image 968 mIoU: 0.9534\n",
      "Image 969 mIoU: 0.9078\n",
      "Image 970 mIoU: 0.9462\n",
      "Image 971 mIoU: 0.9389\n",
      "Image 972 mIoU: 0.9246\n",
      "Image 973 mIoU: 0.9181\n",
      "Image 974 mIoU: 0.9546\n",
      "Image 975 mIoU: 0.9494\n",
      "Image 976 mIoU: 0.9597\n",
      "Image 977 mIoU: 0.9428\n",
      "Image 978 mIoU: 0.9296\n",
      "Image 979 mIoU: 0.9476\n",
      "Image 980 mIoU: 0.9522\n",
      "Image 981 mIoU: 0.9227\n",
      "Image 982 mIoU: 0.9236\n",
      "Image 983 mIoU: 0.9629\n",
      "Image 984 mIoU: 0.9507\n",
      "Image 985 mIoU: 0.9615\n",
      "Image 986 mIoU: 0.9234\n",
      "Image 987 mIoU: 0.9368\n",
      "Image 988 mIoU: 0.9322\n",
      "Image 989 mIoU: 0.9360\n",
      "Image 990 mIoU: 0.9314\n",
      "Image 991 mIoU: 0.9588\n",
      "Image 992 mIoU: 0.9059\n",
      "Image 993 mIoU: 0.9338\n",
      "Image 994 mIoU: 0.9504\n",
      "Image 995 mIoU: 0.9562\n",
      "Image 996 mIoU: 0.9518\n",
      "Image 997 mIoU: 0.9328\n",
      "Image 998 mIoU: 0.9521\n",
      "Image 999 mIoU: 0.9182\n",
      "Image 1000 mIoU: 0.9042\n",
      "\n",
      "✅ Average mIoU over 1000 samples: 0.9347\n"
     ]
    }
   ],
   "source": [
    "eval_miou()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd80585",
   "metadata": {},
   "source": [
    "## calcuate confusion martix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767551a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def compute_confusion_matrix(preds, labels, num_classes):\n",
    "    \"\"\"\n",
    "    preds: Tensor[B, H, W] - 预测标签\n",
    "    labels: Tensor[B, H, W] - 真实标签\n",
    "    return: (num_classes, num_classes) 混淆矩阵\n",
    "    \"\"\"\n",
    "    preds = preds.view(-1).cpu().numpy()\n",
    "    labels = labels.view(-1).cpu().numpy()\n",
    "    mask = (labels >= 0) & (labels < num_classes)\n",
    "    conf_matrix = np.bincount(\n",
    "        num_classes * labels[mask] + preds[mask],\n",
    "        minlength=num_classes**2\n",
    "    ).reshape(num_classes, num_classes)\n",
    "    return conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e816206",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model_confusion(model, dataloader, num_classes=5, max_samples=None):\n",
    "    model.eval()\n",
    "    total_conf_matrix = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "    count = 0\n",
    "\n",
    "    for i, (images, masks) in enumerate(dataloader):\n",
    "        if max_samples is not None and count >= max_samples:\n",
    "            break\n",
    "\n",
    "        images = images.cuda()\n",
    "        masks = masks.cuda()\n",
    "\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        conf = compute_confusion_matrix(preds, masks, num_classes)\n",
    "        total_conf_matrix += conf\n",
    "        count += images.size(0)\n",
    "\n",
    "    print(\"✅ 混淆矩阵（行=真实，列=预测）:\")\n",
    "    print(total_conf_matrix)\n",
    "\n",
    "    # 可选：计算mIoU\n",
    "    ious = []\n",
    "    for i in range(num_classes):\n",
    "        tp = total_conf_matrix[i, i]\n",
    "        fn = total_conf_matrix[i, :].sum() - tp\n",
    "        fp = total_conf_matrix[:, i].sum() - tp\n",
    "        denom = tp + fp + fn\n",
    "        if denom == 0:\n",
    "            iou = np.nan\n",
    "        else:\n",
    "            iou = tp / denom\n",
    "        ious.append(iou)\n",
    "        print(f\"Class {i}: IoU = {iou:.4f}\")\n",
    "\n",
    "    mean_iou = np.nanmean(ious)\n",
    "    print(f\"✅ Evaluated {count} image(s) for confusion matrix and mIoU.\")\n",
    "    print(f\"\\n✅ Mean IoU: {mean_iou:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4948c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_confusion_martix():\n",
    "    # 修改为你的路径\n",
    "    model_path = \"Train_01.pth\"\n",
    "    image_dir = img_path\n",
    "    mask_dir = mask_path\n",
    "    num_classes = 5\n",
    "\n",
    "    # 加载模型\n",
    "    model = SegNet(num_classes=num_classes)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.cuda()\n",
    "\n",
    "    # 数据变换\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # 数据加载\n",
    "    dataset = SegmentationDataset(image_dir, mask_dir, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # 验证模型\n",
    "    evaluate_model_confusion(model, dataloader, num_classes=num_classes, max_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1921c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6820/1464590239.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 混淆矩阵（行=真实，列=预测）:\n",
      "[[46279618   301110   345828    24995        0]\n",
      " [  295013  8784001    44812        0        0]\n",
      " [  256040    54926  8923974        0        0]\n",
      " [   15588      710        8   209377        0]\n",
      " [       0        0        0        0        0]]\n",
      "Class 0: IoU = 0.9739\n",
      "Class 1: IoU = 0.9265\n",
      "Class 2: IoU = 0.9271\n",
      "Class 3: IoU = 0.8352\n",
      "Class 4: IoU = nan\n",
      "✅ Evaluated 1000 image(s) for confusion matrix and mIoU.\n",
      "\n",
      "✅ Mean IoU: 0.9157\n"
     ]
    }
   ],
   "source": [
    "eval_confusion_martix()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871279e4",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a42ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
